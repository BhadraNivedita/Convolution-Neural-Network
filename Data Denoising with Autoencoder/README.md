# Autoencoder_data_denoising
Dirty Data denoising with autoencoder


## Objective: 
This projects cleans noisy images of text data using an AutoEncoder with Keras and TensorFlow Backend.

## Dataset 
The dataset can be found in Kaggle website: https://www.kaggle.com/c/denoising-dirty-documents


## Denoising of dirty textdata


There are innumerable important documents such a scientific papers, historical documentaries, recepits and most importantly old books were written by hand or typewriter. Over the time those written paper documents accumulate dirts from various sources such as fingerprints, abrasions, weakening of wrinkling of paper fibres. Traditional surface cleaning methods sometimes alters the document itself. One of the recent popular digital methods is implementing Autoencoder-a deep neural network application.


## References: 
Some of the references I took help from are:

1. https://codahead.com/blog/a-denoising-autoencoder-for-cifar-datasets

2. https://medium.com/illuin/cleaning-up-dirty-scanned-documents-with-deep-learning-2e8e6de6cfa6

3.https://towardsdatascience.com/applied-deep-learning-part-3-autoencoders-1c083af4d798

4.https://towardsdatascience.com/denoising-noisy-documents-6807c34730c4

5.https://www.kaggle.com/aakashnain/denoising-autoencoders-to-the-rescue


