{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "sixth-therapist",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from scipy.misc import *\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "import os,sys\n",
    "from PIL import Image\n",
    "import cv2 #OpenCV library\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "joined-joseph",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_HOME_DIR = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "corrected-concentration",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/nbhadra/Downloads/Computational/Phenotype_trajectory/Codes/Github_repo_Nivedita/Age-Detection-of-Indian-Actors-master 2'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'/Users/nbhadra/Downloads/Computational/Phenotype_trajectory/Codes/Github_repo_Nivedita/Age-Detection-of-Indian-Actors-master 2'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "thirty-passion",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Age_detection_indian_actors.ipynb\n",
      "Keras_CNN_Age_Detection.ipynb\n",
      "Keras_CNN_Age_Detection_Improved.ipynb\n",
      "README.md\n",
      "ResNet+LRScheduleOnSGD(ExpDecay)+HalfPrecision.ipynb\n",
      "Sample_Submission.csv\n",
      "\u001b[34mTest\u001b[m\u001b[m/\n",
      "\u001b[34mTrain\u001b[m\u001b[m/\n",
      "TrainingWithFastai.ipynb\n",
      "age-detection_weights.h5\n",
      "\u001b[34mdataset\u001b[m\u001b[m/\n",
      "initial_weights.h5\n",
      "leakyReLU_age-detection_weights.h5\n",
      "\u001b[34msub\u001b[m\u001b[m/\n",
      "sub.csv\n",
      "sub03_2_leakyReLU.csv\n",
      "test.csv\n",
      "train.csv\n",
      "Age_detection_indian_actors.ipynb\n",
      "Keras_CNN_Age_Detection.ipynb\n",
      "Keras_CNN_Age_Detection_Improved.ipynb\n",
      "README.md\n",
      "ResNet+LRScheduleOnSGD(ExpDecay)+HalfPrecision.ipynb\n",
      "Sample_Submission.csv\n",
      "\u001b[34mTest\u001b[m\u001b[m/\n",
      "\u001b[34mTrain\u001b[m\u001b[m/\n",
      "TrainingWithFastai.ipynb\n",
      "age-detection_weights.h5\n",
      "\u001b[34mdataset\u001b[m\u001b[m/\n",
      "initial_weights.h5\n",
      "leakyReLU_age-detection_weights.h5\n",
      "\u001b[34msub\u001b[m\u001b[m/\n",
      "sub.csv\n",
      "sub03_2_leakyReLU.csv\n",
      "test.csv\n",
      "train.csv\n"
     ]
    }
   ],
   "source": [
    "%ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "official-drain",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cardiac-upset",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_PATH = DATA_HOME_DIR + '/Train/'\n",
    "TEST_PATH = DATA_HOME_DIR + '/Test/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "special-bullet",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to read images as arrays\n",
    "def read_image(img_path, mode = 'color', resize = False, size = 32):\n",
    "    '''\n",
    "    Default mode is : color(BGR) --> color(RGB)\n",
    "    Other modes allowed are : 'grayscale' and 'include_opacity'\n",
    "    '''\n",
    "    if mode == 'grayscale':\n",
    "        img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "    elif mode == 'include_opacity':\n",
    "        img = cv2.imread(img_path, cv2.IMREAD_UNCHANGED)\n",
    "    else:\n",
    "        img = cv2.imread(img_path, cv2.IMREAD_COLOR)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    if resize == True:\n",
    "        img = cv2.resize(img, (size, size))\n",
    "    \n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "increasing-bridge",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19906/19906 [00:31<00:00, 624.42it/s]\n",
      "  0%|          | 0/6636 [00:00<?, ?it/s]\n",
      "100%|██████████| 6636/6636 [00:07<00:00, 930.98it/s] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Storing all images as list of arrays\n",
    "train_data = []\n",
    "test_data = []\n",
    "\n",
    "for img in tqdm(train['ID'].values):\n",
    "    train_data.append(read_image(TRAIN_PATH + '{}'.format(img), resize = True, size = 32))\n",
    "    \n",
    "for img in tqdm(test['ID'].values):\n",
    "    test_data.append(read_image(TEST_PATH + '{}'.format(img), resize = True, size = 32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "likely-capitol",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train['Class'].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "requested-bermuda",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Checking dimensions and aspect ratio of original images (without resizing)\n",
    "rows = [x.shape[0] for x in (train_data+test_data)]\n",
    "cols = [x.shape[1] for x in (train_data+test_data)]\n",
    "channels = [x.shape[2] for x in (train_data+test_data)]\n",
    "aspect_ratio = [x.shape[0]/x.shape[1] for x in (train_data+test_data)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "reserved-ethics",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min. and Max. rows = 32 and 32 respectively \n",
      "Min. and Max. cols = 32 and 32 respectively \n",
      "Min. and Max. channels = 3 and 3 respectively \n",
      "Min. and Max. aspect ratio = 1.0 and 1.0 respectively \n",
      "\n",
      "Min. and Max. rows = 32 and 32 respectively \n",
      "Min. and Max. cols = 32 and 32 respectively \n",
      "Min. and Max. channels = 3 and 3 respectively \n",
      "Min. and Max. aspect ratio = 1.0 and 1.0 respectively \n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Checking range of the dimesnions and aspect ratio\n",
    "print(\"Min. and Max. rows = {} and {} respectively \\nMin. and Max. cols = {} and {} respectively \\nMin. and Max. channels = {} and {} respectively \\nMin. and Max. aspect ratio = {} and {} respectively \\n\"\n",
    "      .format(min(rows), max(rows), min(cols), max(cols), min(channels), max(channels), min(aspect_ratio), max(aspect_ratio)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "increased-provision",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Class</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>MIDDLE</th>\n",
       "      <td>10804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OLD</th>\n",
       "      <td>2396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>YOUNG</th>\n",
       "      <td>6706</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           ID\n",
       "Class        \n",
       "MIDDLE  10804\n",
       "OLD      2396\n",
       "YOUNG    6706"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Class</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>MIDDLE</th>\n",
       "      <td>10804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OLD</th>\n",
       "      <td>2396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>YOUNG</th>\n",
       "      <td>6706</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           ID\n",
       "Class        \n",
       "MIDDLE  10804\n",
       "OLD      2396\n",
       "YOUNG    6706"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.groupby(by = \"Class\").count()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "sonic-webmaster",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Age_detection_indian_actors.ipynb\n",
      "Keras_CNN_Age_Detection.ipynb\n",
      "Keras_CNN_Age_Detection_Improved.ipynb\n",
      "README.md\n",
      "ResNet+LRScheduleOnSGD(ExpDecay)+HalfPrecision.ipynb\n",
      "Sample_Submission.csv\n",
      "\u001b[34mTest\u001b[m\u001b[m/\n",
      "\u001b[34mTrain\u001b[m\u001b[m/\n",
      "TrainingWithFastai.ipynb\n",
      "age-detection_weights.h5\n",
      "\u001b[34mdataset\u001b[m\u001b[m/\n",
      "initial_weights.h5\n",
      "leakyReLU_age-detection_weights.h5\n",
      "\u001b[34msub\u001b[m\u001b[m/\n",
      "sub.csv\n",
      "sub03_2_leakyReLU.csv\n",
      "test.csv\n",
      "train.csv\n",
      "Age_detection_indian_actors.ipynb\n",
      "Keras_CNN_Age_Detection.ipynb\n",
      "Keras_CNN_Age_Detection_Improved.ipynb\n",
      "README.md\n",
      "ResNet+LRScheduleOnSGD(ExpDecay)+HalfPrecision.ipynb\n",
      "Sample_Submission.csv\n",
      "\u001b[34mTest\u001b[m\u001b[m/\n",
      "\u001b[34mTrain\u001b[m\u001b[m/\n",
      "TrainingWithFastai.ipynb\n",
      "age-detection_weights.h5\n",
      "\u001b[34mdataset\u001b[m\u001b[m/\n",
      "initial_weights.h5\n",
      "leakyReLU_age-detection_weights.h5\n",
      "\u001b[34msub\u001b[m\u001b[m/\n",
      "sub.csv\n",
      "sub03_2_leakyReLU.csv\n",
      "test.csv\n",
      "train.csv\n"
     ]
    }
   ],
   "source": [
    "%ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "realistic-composition",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fd8058ba290>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fd8058ba290>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Displaying random images without resizing\n",
    "i = np.random.choice(np.arange(len(train_data)))\n",
    "\n",
    "plt.title('{} - {} ; shape : {}'.format(train['ID'].values[i], y_train[i], train_data[i].shape))\n",
    "plt.imshow(train_data[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "frozen-stick",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Scaling the images\n",
    "X_train = np.array(train_data, np.float32) / 255.\n",
    "X_test = np.array(test_data, np.float32) / 255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ready-stranger",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoding image labels into target variables (categorical)\n",
    "from sklearn.preprocessing import LabelEncoder,OneHotEncoder\n",
    "le = LabelEncoder()\n",
    "y_train = le.fit_transform(y_train)\n",
    "\n",
    "ohe = OneHotEncoder()\n",
    "y_train = ohe.fit_transform(y_train.reshape(-1,1)).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "strategic-brake",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19906, 3)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(19906, 3)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "classical-airplane",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the Keras libraries and packages\n",
    "import keras\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import *\n",
    "from keras.layers.advanced_activations import PReLU, LeakyReLU, ELU\n",
    "from keras.optimizers import SGD\n",
    "from keras.constraints import maxnorm\n",
    "\n",
    "from keras import backend as K\n",
    "#K.set_image_dim_ordering('tf')\n",
    "\n",
    "from keras.preprocessing import image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "handled-programming",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#os.environ['KERAS_BACKEND'] = 'theano'\n",
    "#reload(K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fiscal-accounting",
   "metadata": {},
   "outputs": [],
   "source": [
    "        \n",
    "model = Sequential([\n",
    "        BatchNormalization(input_shape = (32,32,3)),\n",
    "        Convolution2D(32,(3,3), activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Convolution2D(32,(3,3), activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        MaxPooling2D(),\n",
    "        Convolution2D(64,(3,3), activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Convolution2D(64,(3,3), activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        MaxPooling2D(),\n",
    "        Flatten(),\n",
    "        Dropout(0.3),\n",
    "        Dense(384, activation='relu'),\n",
    "        Dropout(0.6),\n",
    "        Dense(3, activation='softmax')\n",
    "        ])\n",
    "model.compile(optimizer = 'adam' , loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "satisfactory-ozone",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Saving initial un-trained weights for future use\n",
    "model.save_weights('initial_weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ethical-inspiration",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "batch_normalization (BatchNo (None, 32, 32, 3)         12        \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 30, 30, 32)        896       \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 30, 30, 32)        128       \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 28, 28, 32)        9248      \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 28, 28, 32)        128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 12, 12, 64)        18496     \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 12, 12, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 10, 10, 64)        36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 10, 10, 64)        256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1600)              0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 1600)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 384)               614784    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 384)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 3)                 1155      \n",
      "=================================================================\n",
      "Total params: 682,287\n",
      "Trainable params: 681,897\n",
      "Non-trainable params: 390\n",
      "_________________________________________________________________\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "batch_normalization (BatchNo (None, 32, 32, 3)         12        \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 30, 30, 32)        896       \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 30, 30, 32)        128       \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 28, 28, 32)        9248      \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 28, 28, 32)        128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 12, 12, 64)        18496     \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 12, 12, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 10, 10, 64)        36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 10, 10, 64)        256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1600)              0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 1600)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 384)               614784    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 384)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 3)                 1155      \n",
      "=================================================================\n",
      "Total params: 682,287\n",
      "Trainable params: 681,897\n",
      "Non-trainable params: 390\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "armed-norwegian",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "        BatchNormalization(input_shape = (128,128,3)),\n",
    "        Convolution2D(32,(3,3), activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Convolution2D(32,(3,3), activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        MaxPooling2D(),\n",
    "        Convolution2D(64,(3,3), activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Convolution2D(64,(3,3), activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        MaxPooling2D(),\n",
    "        Convolution2D(64,(3,3), activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        MaxPooling2D(),\n",
    "        Convolution2D(64,(3,3), activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        MaxPooling2D(),\n",
    "        Flatten(),\n",
    "        Dropout(0.3),\n",
    "        Dense(512, activation='relu'),\n",
    "        Dropout(0.6),\n",
    "        Dense(3, activation='softmax')\n",
    "        ])\n",
    "model.compile(optimizer = 'adam' , loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "consecutive-timothy",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Saving initial un-trained weights for future use\n",
    "model.save_weights('initial_weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "caring-chester",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = Sequential([\n",
    "        BatchNormalization(input_shape = (32,32,3)),\n",
    "        Convolution2D(32,(3,3), activation='linear'),\n",
    "        LeakyReLU(alpha = 0.3),\n",
    "        BatchNormalization(),\n",
    "        Convolution2D(32,(3,3), activation='linear'),\n",
    "        LeakyReLU(alpha = 0.3),\n",
    "        BatchNormalization(),\n",
    "        MaxPooling2D(),\n",
    "        Convolution2D(64,(3,3), activation='linear'),\n",
    "        LeakyReLU(alpha = 0.3),\n",
    "        BatchNormalization(),\n",
    "        Convolution2D(64,(3,3), activation='linear'),\n",
    "        LeakyReLU(alpha = 0.3),\n",
    "        BatchNormalization(),\n",
    "        MaxPooling2D(),\n",
    "        Flatten(),\n",
    "        Dropout(0.3),\n",
    "        Dense(384, activation='linear'),\n",
    "        LeakyReLU(alpha = 0.3),\n",
    "        Dropout(0.6),\n",
    "        Dense(3, activation='softmax')\n",
    "        ])\n",
    "model.compile(optimizer = 'adam' , loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "complex-chemical",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## Saving initial un-trained weights for future use\n",
    "model.save_weights('initial_weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "civilian-trail",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "batch_normalization_12 (Batc (None, 32, 32, 3)         12        \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 30, 30, 32)        896       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu (LeakyReLU)      (None, 30, 30, 32)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_13 (Batc (None, 30, 30, 32)        128       \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 28, 28, 32)        9248      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 28, 28, 32)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_14 (Batc (None, 28, 28, 32)        128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 12, 12, 64)        18496     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)    (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_15 (Batc (None, 12, 12, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv2d_13 (Conv2D)           (None, 10, 10, 64)        36928     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)    (None, 10, 10, 64)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_16 (Batc (None, 10, 10, 64)        256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 1600)              0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 1600)              0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 384)               614784    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)    (None, 384)               0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 384)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 3)                 1155      \n",
      "=================================================================\n",
      "Total params: 682,287\n",
      "Trainable params: 681,897\n",
      "Non-trainable params: 390\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "batch_normalization_12 (Batc (None, 32, 32, 3)         12        \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 30, 30, 32)        896       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu (LeakyReLU)      (None, 30, 30, 32)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_13 (Batc (None, 30, 30, 32)        128       \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 28, 28, 32)        9248      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 28, 28, 32)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_14 (Batc (None, 28, 28, 32)        128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 12, 12, 64)        18496     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)    (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_15 (Batc (None, 12, 12, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv2d_13 (Conv2D)           (None, 10, 10, 64)        36928     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)    (None, 10, 10, 64)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_16 (Batc (None, 10, 10, 64)        256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 1600)              0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 1600)              0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 384)               614784    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)    (None, 384)               0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 384)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 3)                 1155      \n",
      "=================================================================\n",
      "Total params: 682,287\n",
      "Trainable params: 681,897\n",
      "Non-trainable params: 390\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "structural-engineer",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Building a custom function for learning rate decay/annealing\n",
    "def lr_decay(start, stop, div_step_1, div_step_2 = 2) :\n",
    "    k = 1\n",
    "    while start >= stop:\n",
    "        yield start\n",
    "        if k==1 :\n",
    "            start/= div_step_1\n",
    "        else : start/= div_step_2\n",
    "        k = k * -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "veterinary-pathology",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "Epoch 1/2\n",
      "498/498 [==============================] - 60s 121ms/step - loss: 1.2543 - accuracy: 0.5881 - val_loss: 0.7692 - val_accuracy: 0.6630\n",
      "498/498 [==============================] - 60s 121ms/step - loss: 1.2543 - accuracy: 0.5881 - val_loss: 0.7692 - val_accuracy: 0.6630\n",
      "Epoch 2/2\n",
      "  1/498 [..............................] - ETA: 0s - loss: 1.0499 - accuracy: 0.5312Epoch 2/2\n",
      "498/498 [==============================] - 60s 120ms/step - loss: 0.7756 - accuracy: 0.6652 - val_loss: 0.7032 - val_accuracy: 0.6931\n",
      "498/498 [==============================] - 60s 120ms/step - loss: 0.7756 - accuracy: 0.6652 - val_loss: 0.7032 - val_accuracy: 0.6931\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fd7dddaa590>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fd7dddaa590>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training the model\n",
    "model.fit(X_train, y_train, batch_size=32, epochs=2, validation_split=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "political-harvest",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.optimizer.lr = model.optimizer.lr /10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "bound-pattern",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Saving weights as a form of model checkpointing\n",
    "model.save_weights('age-detection_weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "artistic-lingerie",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_trn, X_valid, y_trn, y_valid = train_test_split(X_train, y_train, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "early-victory",
   "metadata": {},
   "outputs": [],
   "source": [
    "gen = image.ImageDataGenerator(rotation_range=15, width_shift_range=0.1, shear_range=0.25,\n",
    "                               height_shift_range=0.1, zoom_range=0.2, horizontal_flip = True)\n",
    "batches = gen.flow(X_trn, y_trn, batch_size = 64)\n",
    "val_batches = gen.flow(X_valid, y_valid, batch_size = 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "stone-raleigh",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.optimizer.lr = 0.001\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "close-programmer",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-35-47d0ed01ab03>:2: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use Model.fit, which supports generators.\n",
      "WARNING:tensorflow:From <ipython-input-35-47d0ed01ab03>:2: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use Model.fit, which supports generators.\n",
      "248/248 [==============================] - 53s 214ms/step - loss: 0.7616 - accuracy: 0.6691 - val_loss: 0.7027 - val_accuracy: 0.6946\n",
      "248/248 [==============================] - 53s 214ms/step - loss: 0.7616 - accuracy: 0.6691 - val_loss: 0.7027 - val_accuracy: 0.6946\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fd7bf7849d0>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fd7bf7849d0>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "model.fit_generator(batches, (X_trn.shape[0]//batches.batch_size), epochs=1,\n",
    "                    validation_data = val_batches, validation_steps = (X_valid.shape[0]//val_batches.batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "stone-brazil",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.optimizer.lr = (1/10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "second-rabbit",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "Epoch 1/2\n",
      "248/248 [==============================] - 52s 211ms/step - loss: 1064.3918 - accuracy: 0.4207 - val_loss: 360.8619 - val_accuracy: 0.1296\n",
      "248/248 [==============================] - 52s 211ms/step - loss: 1064.3918 - accuracy: 0.4207 - val_loss: 360.8619 - val_accuracy: 0.1296\n",
      "Epoch 2/2\n",
      "Epoch 2/2\n",
      "248/248 [==============================] - 53s 213ms/step - loss: 23.2301 - accuracy: 0.4249 - val_loss: 4.4942 - val_accuracy: 0.5347\n",
      "248/248 [==============================] - 53s 213ms/step - loss: 23.2301 - accuracy: 0.4249 - val_loss: 4.4942 - val_accuracy: 0.5347\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fd7bf6bb610>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fd7bf6bb610>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(batches, steps_per_epoch = (X_trn.shape[0]//batches.batch_size), epochs=2,\n",
    "                    validation_data = val_batches, validation_steps = (X_valid.shape[0]/val_batches.batch_size))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "south-pharmaceutical",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate = 0.005\n",
      "Learning rate = 0.005\n",
      "248/248 [==============================] - 56s 226ms/step - loss: 4.0031 - accuracy: 0.4401 - val_loss: 1.6343 - val_accuracy: 0.5365\n",
      "248/248 [==============================] - 56s 226ms/step - loss: 4.0031 - accuracy: 0.4401 - val_loss: 1.6343 - val_accuracy: 0.5365\n",
      "Learning rate = 0.0025\n",
      "Learning rate = 0.0025\n",
      "248/248 [==============================] - 56s 227ms/step - loss: 2.3110 - accuracy: 0.4433 - val_loss: 1.5650 - val_accuracy: 0.5378\n",
      "248/248 [==============================] - 56s 227ms/step - loss: 2.3110 - accuracy: 0.4433 - val_loss: 1.5650 - val_accuracy: 0.5378\n",
      "Learning rate = 0.0005\n",
      "Learning rate = 0.0005\n",
      "248/248 [==============================] - 52s 211ms/step - loss: 1.9819 - accuracy: 0.4537 - val_loss: 1.3699 - val_accuracy: 0.5376\n",
      "248/248 [==============================] - 52s 211ms/step - loss: 1.9819 - accuracy: 0.4537 - val_loss: 1.3699 - val_accuracy: 0.5376\n",
      "Learning rate = 0.00025\n",
      "Learning rate = 0.00025\n",
      "248/248 [==============================] - 53s 214ms/step - loss: 1.9804 - accuracy: 0.4477 - val_loss: 1.2807 - val_accuracy: 0.5403\n",
      "248/248 [==============================] - 53s 214ms/step - loss: 1.9804 - accuracy: 0.4477 - val_loss: 1.2807 - val_accuracy: 0.5403\n"
     ]
    }
   ],
   "source": [
    "for i in lr_decay(0.005, 0.0002, 2, 5):\n",
    "    model.optimizer.lr = i\n",
    "    print(\"Learning rate = \" + str(i))\n",
    "    model.fit_generator(batches, (X_trn.shape[0]//batches.batch_size), epochs=1,\n",
    "                    validation_data = val_batches, validation_steps = (X_valid.shape[0]//val_batches.batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "prescribed-beatles",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Saving weights as a form of model checkpointing\n",
    "model.save_weights('leakyReLU_age-detection_weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "played-diesel",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "skf = StratifiedKFold(n_splits = 5, shuffle = True, random_state = 102)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "relevant-peninsula",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Supported target types are: ('binary', 'multiclass'). Got 'multilabel-indicator' instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-41-1bb06a8b8e58>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mtrain_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_idx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mskf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Fitting fold %d\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0mfold_num\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;31m# Data augmentation image generator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     gen = image.ImageDataGenerator(rotation_range=15, width_shift_range=0.1, shear_range=0.25,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36msplit\u001b[0;34m(self, X, y, groups)\u001b[0m\n\u001b[1;32m    334\u001b[0m                 .format(self.n_splits, n_samples))\n\u001b[1;32m    335\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 336\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    337\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    338\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36msplit\u001b[0;34m(self, X, y, groups)\u001b[0m\n\u001b[1;32m     78\u001b[0m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindexable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m         \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_num_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mtest_index\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iter_test_masks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m             \u001b[0mtrain_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogical_not\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m             \u001b[0mtest_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36m_iter_test_masks\u001b[0;34m(self, X, y, groups)\u001b[0m\n\u001b[1;32m    695\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    696\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_iter_test_masks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 697\u001b[0;31m         \u001b[0mtest_folds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_test_folds\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    698\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_splits\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    699\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0mtest_folds\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36m_make_test_folds\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    649\u001b[0m             raise ValueError(\n\u001b[1;32m    650\u001b[0m                 'Supported target types are: {}. Got {!r} instead.'.format(\n\u001b[0;32m--> 651\u001b[0;31m                     allowed_target_types, type_of_target_y))\n\u001b[0m\u001b[1;32m    652\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    653\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcolumn_or_1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Supported target types are: ('binary', 'multiclass'). Got 'multilabel-indicator' instead."
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Supported target types are: ('binary', 'multiclass'). Got 'multilabel-indicator' instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-41-1bb06a8b8e58>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mtrain_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_idx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mskf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Fitting fold %d\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0mfold_num\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;31m# Data augmentation image generator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     gen = image.ImageDataGenerator(rotation_range=15, width_shift_range=0.1, shear_range=0.25,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36msplit\u001b[0;34m(self, X, y, groups)\u001b[0m\n\u001b[1;32m    334\u001b[0m                 .format(self.n_splits, n_samples))\n\u001b[1;32m    335\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 336\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    337\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    338\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36msplit\u001b[0;34m(self, X, y, groups)\u001b[0m\n\u001b[1;32m     78\u001b[0m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindexable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m         \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_num_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mtest_index\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iter_test_masks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m             \u001b[0mtrain_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogical_not\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m             \u001b[0mtest_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36m_iter_test_masks\u001b[0;34m(self, X, y, groups)\u001b[0m\n\u001b[1;32m    695\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    696\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_iter_test_masks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 697\u001b[0;31m         \u001b[0mtest_folds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_test_folds\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    698\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_splits\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    699\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0mtest_folds\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36m_make_test_folds\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    649\u001b[0m             raise ValueError(\n\u001b[1;32m    650\u001b[0m                 'Supported target types are: {}. Got {!r} instead.'.format(\n\u001b[0;32m--> 651\u001b[0;31m                     allowed_target_types, type_of_target_y))\n\u001b[0m\u001b[1;32m    652\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    653\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcolumn_or_1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Supported target types are: ('binary', 'multiclass'). Got 'multilabel-indicator' instead."
     ]
    }
   ],
   "source": [
    "for train_idx, val_idx in skf.split(X_train,y_train):\n",
    "    print(\"Fitting fold %d\" %fold_num)\n",
    "    \n",
    "    # Data augmentation image generator\n",
    "    gen = image.ImageDataGenerator(rotation_range=15, width_shift_range=0.1, shear_range=0.25,\n",
    "                               height_shift_range=0.1, zoom_range=0.2, horizontal_flip = True)\n",
    "    batches = gen.flow(X_train[train_idx], y_train[train_idx], batch_size = 32)\n",
    "    val_batches = gen.flow(X_train[val_idx], y_train[val_idx], batch_size = 64)\n",
    "    \n",
    "    # Fitting the model\n",
    "    model.fit_generator(batches, steps_per_epoch = (X_trn.shape[0]//batches.batch_size), epochs=3,\n",
    "                    validation_data = val_batches, validation_steps = (X_valid.shape[0]//val_batches.batch_size))\n",
    "    \n",
    "    # Recompiling the model with initial weights\n",
    "    model.load_weights('initial_weights.h5')\n",
    "    \n",
    "    fold_num += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "reduced-danish",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Building the autoencoder pipeline\n",
    "\n",
    "input_img = Input(shape=(32, 32, 3))\n",
    "x = Conv2D(32, (3, 3), activation='relu', padding='same')(input_img)\n",
    "x = MaxPooling2D((2, 2), padding='same')(x)\n",
    "x = Conv2D(16, (3, 3), activation='relu', padding='same')(x)\n",
    "x = MaxPooling2D((2, 2), padding='same')(x)\n",
    "x = Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
    "encoded = MaxPooling2D((2, 2), padding='same')(x)\n",
    "\n",
    "# at this point the representation is (8, 4, 4, 3) i.e. 384-dimensional\n",
    "\n",
    "x = Conv2D(8, (3, 3), activation='relu', padding='same')(encoded)\n",
    "x = UpSampling2D((2, 2))(x)\n",
    "x = Conv2D(16, (3, 3), activation='relu', padding='same')(x)\n",
    "x = UpSampling2D((2, 2))(x)\n",
    "x = Conv2D(32, (3, 3), activation='relu', padding = 'same')(x)\n",
    "x = UpSampling2D((2, 2))(x)\n",
    "decoded = Conv2D(3, (3, 3), activation='sigmoid', padding='same')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "impossible-career",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## Composing the autoencoder model and compiling it\n",
    "autoencoder = Model(input_img, decoded)\n",
    "autoencoder.compile(optimizer='adadelta', loss='binary_crossentropy') # can change optimizer to 'adam'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "lasting-poster",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 32, 32, 3)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d_14 (Conv2D)           (None, 32, 32, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2 (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_15 (Conv2D)           (None, 16, 16, 16)        4624      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2 (None, 8, 8, 16)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_16 (Conv2D)           (None, 8, 8, 8)           1160      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling (None, 4, 4, 8)           0         \n",
      "_________________________________________________________________\n",
      "conv2d_17 (Conv2D)           (None, 4, 4, 8)           584       \n",
      "_________________________________________________________________\n",
      "up_sampling2d (UpSampling2D) (None, 8, 8, 8)           0         \n",
      "_________________________________________________________________\n",
      "conv2d_18 (Conv2D)           (None, 8, 8, 16)          1168      \n",
      "_________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2 (None, 16, 16, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_19 (Conv2D)           (None, 16, 16, 32)        4640      \n",
      "_________________________________________________________________\n",
      "up_sampling2d_2 (UpSampling2 (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_20 (Conv2D)           (None, 32, 32, 3)         867       \n",
      "=================================================================\n",
      "Total params: 13,939\n",
      "Trainable params: 13,939\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 32, 32, 3)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d_14 (Conv2D)           (None, 32, 32, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2 (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_15 (Conv2D)           (None, 16, 16, 16)        4624      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2 (None, 8, 8, 16)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_16 (Conv2D)           (None, 8, 8, 8)           1160      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling (None, 4, 4, 8)           0         \n",
      "_________________________________________________________________\n",
      "conv2d_17 (Conv2D)           (None, 4, 4, 8)           584       \n",
      "_________________________________________________________________\n",
      "up_sampling2d (UpSampling2D) (None, 8, 8, 8)           0         \n",
      "_________________________________________________________________\n",
      "conv2d_18 (Conv2D)           (None, 8, 8, 16)          1168      \n",
      "_________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2 (None, 16, 16, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_19 (Conv2D)           (None, 16, 16, 32)        4640      \n",
      "_________________________________________________________________\n",
      "up_sampling2d_2 (UpSampling2 (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_20 (Conv2D)           (None, 32, 32, 3)         867       \n",
      "=================================================================\n",
      "Total params: 13,939\n",
      "Trainable params: 13,939\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "autoencoder.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "expired-personal",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import TensorBoard\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "under-listing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "Epoch 1/10\n",
      "312/312 [==============================] - 45s 145ms/step - loss: 0.6935 - val_loss: 0.6934\n",
      "312/312 [==============================] - 45s 145ms/step - loss: 0.6935 - val_loss: 0.6934\n",
      "Epoch 2/10\n",
      "  1/312 [..............................] - ETA: 0s - loss: 0.6933Epoch 2/10\n",
      "270/312 [========================>.....] - ETA: 5s - loss: 0.6932"
     ]
    }
   ],
   "source": [
    "## Fitting the autoencoder model\n",
    "autoencoder.fit(X_train, X_train,\n",
    "                epochs= 10,\n",
    "                batch_size= 64,\n",
    "                shuffle= True,\n",
    "                validation_data= (X_test, X_test))\n",
    "                #callbacks=[TensorBoard(log_dir='/tmp/autoencoder')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "geographic-myanmar",
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder.fit(X_train, X_train,\n",
    "                epochs= 3,\n",
    "                batch_size= 128,\n",
    "                shuffle= True,\n",
    "                validation_data= (X_test, X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "talented-harbor",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoded_imgs = autoencoder.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "urban-pharmaceutical",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(X_test)\n",
    "predictions = np.argmax(predictions, axis= 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "built-donor",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting predicted category numbers to predicted labels\n",
    "unique_labels = np.unique(train['Class'].tolist())\n",
    "pred_labels = unique_labels[predictions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "electrical-johnson",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Let's see what our classifier predicts on test images\n",
    "# Random predictions\n",
    "i = np.random.choice(np.arange(len(test_data)))\n",
    "plt.title('{} - Predicted class : {}'.format(test['ID'].values[i], pred_labels[i]))\n",
    "plt.imshow(test_data[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mounted-clothing",
   "metadata": {},
   "outputs": [],
   "source": [
    "subm = pd.DataFrame({'Class':pred_labels, 'ID':test.ID})\n",
    "subm.to_csv('sub03_2_leakyReLU.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "scientific-stupid",
   "metadata": {},
   "outputs": [],
   "source": [
    "subm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "moral-criminal",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
